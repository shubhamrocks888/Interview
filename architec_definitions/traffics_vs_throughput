If traffic exceeds sustainable throughput, scaling workers alone will worsen the problem,

What does it mean

This is a very important systems concept, and interviewers love it. Letâ€™s break it down calmly and intuitively.

First: what is sustainable throughput?

Sustainable throughput =
ğŸ‘‰ the maximum number of requests per second your system can handle without falling behind.

If your app can:

Process 100 requests/sec

And traffic comes in at 80 requests/sec â†’ âœ… fine

Traffic comes in at 150 requests/sec â†’ âŒ system starts choking

That 100 req/sec is your sustainable throughput.

Now the sentence ğŸ‘‡

â€œIf traffic exceeds sustainable throughput, scaling workers alone will worsen the problem.â€

What it really means

When incoming traffic > what your system can process, simply adding more workers (threads/processes) can actually make things worse, not better.

Why? Because the real bottleneck is elsewhere.

Think of a real-life analogy ğŸš¦
Toll booth example

Road allows 100 cars/min

Toll booth processes 100 cars/min

Now:

Cars arrive at 200 cars/min

What if you:

Add more toll workers

But still have only one lane road?

ğŸ‘‰ Result:

More workers fighting for the same lane

More congestion

Slower overall throughput

The road is the bottleneck, not the workers.

In software terms (Rails-style)

Letâ€™s say:

DB can handle 100 queries/sec

Each request hits DB once

Traffic = 200 req/sec

You add more Puma workers/threads

What happens?

More concurrent DB queries

DB starts:

Locking

Queueing

Context switching

Queries get slower

Requests pile up

Timeouts increase

ğŸ‘‰ Throughput stays the same or drops
ğŸ‘‰ Latency explodes

Why scaling workers makes it worse
1ï¸âƒ£ Contention increases

More threads fighting for:

DB connections

CPU

Locks

2ï¸âƒ£ Context switching overhead

CPU spends time switching instead of working

3ï¸âƒ£ Queue growth

Requests pile up faster than theyâ€™re processed

4ï¸âƒ£ Cascading failures

Timeouts â†’ retries â†’ even more load ğŸ’¥

Key insight (this is the money line)

You canâ€™t out-scale a bottleneck.

If the bottleneck is:

Database

External API

Disk

Network

Adding workers just means:
ğŸ‘‰ more pressure on the same weak point

Correct ways to fix it (instead of just scaling)
If itâ€™s I/O-bound

Add DB indexes

Reduce N+1 queries

Cache (Redis, HTTP cache)

Read replicas

Async / background jobs

Rate limiting

If itâ€™s CPU-bound

Optimize code

Move heavy work to background jobs

Scale horizontally (more machines)

Use faster algorithms

If traffic is simply too high

Backpressure

Queueing

Load shedding

Circuit breakers

Return 429 (Too Many Requests)

One-liner for interviews ğŸ¯

â€œIf incoming traffic exceeds sustainable throughput, adding more workers increases contention on the real bottleneck (like the database), causing higher latency and even lower throughput.â€