Good question â€” this is a very common misunderstanding.

Short answer

ğŸ‘‰ No error is thrown.
Everything â€œworksâ€, but your system silently hurts itself.

What actually happens (no TTL, no race protection)

When expires_in is reached and many requests arrive together:

Rails.cache.fetch("expensive_data") { heavy_computation }

Timeline again
T=0    cache expires
T=0.1  100 requests hit at the same time

For EACH request

Cache lookup â†’ MISS

Rails runs the block

heavy_computation executes

Result written back to cache (last write wins)

â— Important: this is NOT an exception scenario

âŒ No RaceConditionError

âŒ No Redis error

âŒ No Rails error

âŒ No log warning

From Railsâ€™ point of view:

â€œCache miss? Okay, recompute.â€

So what goes wrong?
1ï¸âƒ£ Database / API overload

100 identical expensive queries

DB CPU spikes

Connection pool exhausted

Other requests slow down

2ï¸âƒ£ Cascading failures

Requests become slow

Load balancer retries

Timeouts start happening

Eventually real errors appear, but later

Examples youâ€™ll see:

ActiveRecord::ConnectionTimeoutError

Net::ReadTimeout

502 / 504 at gateway

ğŸ“Œ These are secondary failures, not cache errors.

3ï¸âƒ£ Non-deterministic cache value

All requests recompute

Last one writes value

Usually same data, but:

Time-based queries

External APIs

Partial failures
â†’ Cache ends up with unpredictable value

Why this bug is dangerous

Because:

App works fine in low traffic

No errors in logs

Fails only under load

Looks like â€œrandom slownessâ€

ğŸ“Œ This is why cache stampede bugs survive to production.

With race_condition_ttl, contrast
Rails.cache.fetch(
  "expensive_data",
  expires_in: 10.minutes,
  race_condition_ttl: 5.seconds
) { heavy_computation }


Now:

One request recomputes

Others serve stale data

No DB storm

No hidden failures

Key takeaway (memorize)

Cache stampede does not cause immediate errors â€” it causes silent overload, which later manifests as timeouts and outages.

Interview-ready answer

Without race-condition protection, concurrent cache misses cause multiple expensive recomputations. No error is raised, but the system experiences unnecessary load, leading to timeouts and degraded performance.