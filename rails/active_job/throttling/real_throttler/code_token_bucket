Token Bucket is the cleanest â€œreal throttlerâ€ to learn.

Iâ€™ll implement it step by step, then explain how it maps to real throttling behavior.

1ï¸âƒ£ Token Bucket idea (quick recap)

Bucket has capacity (max tokens)

Tokens refill over time

Each request consumes 1 token

If no token â†’ request is rejected (or delayed)

This allows:

bursts âœ…

average rate enforcement âœ…

smooth throttling âœ…

2ï¸âƒ£ Simple Token Bucket in Ruby (in-memory)
Basic implementation
class TokenBucket
  def initialize(capacity:, refill_rate:)
    @capacity = capacity
    @refill_rate = refill_rate # tokens per second
    @tokens = capacity
    @last_refill = Time.now
  end

  def allow?
    refill_tokens

    if @tokens >= 1
      @tokens -= 1
      true
    else
      false
    end
  end

  private

  def refill_tokens
    now = Time.now
    elapsed = now - @last_refill

    new_tokens = elapsed * @refill_rate
    @tokens = [@capacity, @tokens + new_tokens].min

    @last_refill = now if new_tokens > 0
  end
end

3ï¸âƒ£ How to use it
bucket = TokenBucket.new(
  capacity: 10,
  refill_rate: 1 # 1 token per second
)

if bucket.allow?
  puts "Request allowed"
else
  puts "Throttled"
end

4ï¸âƒ£ What this gives you (important)
Example behavior

capacity = 10

refill_rate = 1 token/sec

| Time              | Tokens | Result        |
| ----------------- | ------ | ------------- |
| Start             | 10     | burst allowed |
| 10 quick requests | 0      | all allowed   |
| Next request      | 0      | blocked       |
| After 3 sec       | 3      | 3 allowed     |
| After long idle   | 10     | full again    |

This is real throttling behavior.

5ï¸âƒ£ Why this is better than fixed-window rate limiting

| Feature         | Fixed Window | Token Bucket |
| --------------- | ------------ | ------------ |
| Burst handling  | âŒ            | âœ…            |
| Smooth refill   | âŒ            | âœ…            |
| Boundary issues | âŒ            | âœ…            |
| Real throttling | âŒ            | âœ…            |

6ï¸âƒ£ But âš ï¸ this version is NOT production-safe

Why?

In-memory â†’ per process only

Not shared across servers

Not atomic

Thread-unsafe

So letâ€™s do production-ready Redis version.

7ï¸âƒ£ Token Bucket using Redis (Rails.cache)
Concept

We store:

token count

last refill timestamp

Implementation
class RedisTokenBucket
  def initialize(capacity:, refill_rate:)
    @capacity = capacity
    @refill_rate = refill_rate
  end

  def allow?(key)
    now = Time.now.to_f

    data = Rails.cache.read(bucket_key(key)) || {
      tokens: @capacity,
      last_refill: now
    }

    tokens = data[:tokens]
    last_refill = data[:last_refill]

    # refill
    elapsed = now - last_refill
    tokens = [@capacity, tokens + elapsed * @refill_rate].min

    if tokens >= 1
      tokens -= 1
      Rails.cache.write(
        bucket_key(key),
        { tokens: tokens, last_refill: now },
        expires_in: ttl
      )
      true
    else
      Rails.cache.write(
        bucket_key(key),
        { tokens: tokens, last_refill: now },
        expires_in: ttl
      )
      false
    end
  end

  private

  def bucket_key(key)
    "token_bucket:#{key}"
  end

  def ttl
    (@capacity / @refill_rate).ceil
  end
end

8ï¸âƒ£ Important interview note âš ï¸

This Redis version is logically correct but still has:

race conditions under concurrency

True production systems use:

Redis Lua scripts

Atomic math in Redis

Or specialized gateways (Envoy, Nginx)

If you mention this â†’ you sound senior ğŸ‘Œ

9ï¸âƒ£ Interview-ready explanation ğŸ¯

You can say:

â€œToken bucket allows short bursts by consuming pre-filled tokens, then enforces an average rate using time-based refill. Itâ€™s closer to real throttling than fixed-window rate limiting.â€

That answer is ğŸ”¥.

ğŸ”Ÿ Final takeaway

âœ”ï¸ Rate limiter â†’ counts requests

âœ”ï¸ Token bucket â†’ controls flow

âœ”ï¸ Your intuition about slow â†’ reject was correct

âœ”ï¸ This is real throttling