Iâ€™ll explain exactly how Sidekiq knows and exactly where Redis is involved.

Step-by-step: Sidekiq crash â†’ restart â†’ job recovery
STEP 0 â€” Before anything runs

A job is sitting in Redis:

queue:default   (Redis LIST)


Nothing special yet.

STEP 1 â€” Worker fetches the job (IMPORTANT)

A Sidekiq worker fetches a job using a reliable fetch:

ğŸ‘‰ Job is NOT deleted
ğŸ‘‰ It is atomically moved

From:

queue:default


To:

queue:default:inprogress   (internal / reliable fetch structure)


This happens in one Redis operation
So Redis now knows:

â€œThis job was taken, but not finished yetâ€

STEP 2 â€” Sidekiq records who is running the job

Sidekiq now writes metadata to Redis:

1ï¸âƒ£ Process heartbeat
processes


Contains Sidekiq process IDs

Updated every ~5 seconds

2ï¸âƒ£ Worker state
workers


Example entry:

{
  "pid": 1234,
  "thread_id": "xyz",
  "queue": "default",
  "jid": "abc123",
  "run_at": 1700000000
}


Redis now knows:
âœ” which process
âœ” which worker
âœ” which job
âœ” start time

STEP 3 â€” ğŸ’¥ Sidekiq process crashes

Example causes:

Server restart

kill -9

OOM kill

Deploy gone wrong

What does NOT happen:
âŒ Job is NOT marked complete
âŒ Job is NOT deleted
âŒ Retry logic is NOT triggered

What does happen:

Heartbeat stops

Worker entry becomes stale

Job remains in inprogress

STEP 4 â€” Sidekiq restarts

This is the key moment.

4.1 Sidekiq scans Redis

On boot, Sidekiq checks:

processes
workers


It finds:

â€œThese processes were running jobs, but they are no longer alive.â€

STEP 5 â€” Sidekiq identifies crashed jobs

Sidekiq compares:

Redis data	Meaning
Worker entry exists	Job was running
Process heartbeat missing	Process crashed

âœ… This combination = crashed job

STEP 6 â€” Sidekiq recovers the job

Now Sidekiq does recovery:

Removes stale worker entries

Moves job payload from:

queue:default:inprogress


back to:

queue:default


At this moment:
ğŸ‘‰ Job is ready to run again

STEP 7 â€” Job runs again

Any worker can pick it up

Job starts from the beginning

Retry count is unchanged (no exception happened)

Why Sidekiq can do this safely

Because of three guarantees:

âœ… Redis operations are atomic

No job can â€œhalf disappearâ€.

âœ… Job acknowledgement happens LAST

Job is removed from Redis only after success.

âœ… Heartbeats detect dead processes

No heartbeat = assume crash.

VERY IMPORTANT INTERVIEW LINE ğŸ”¥

Sidekiq does not need to â€œrememberâ€ crashed jobs â€” they were never removed from Redis in the first place.

Visual flow (easy to remember)
queue â†’ inprogress â†’ (success) delete
                  â†’ (crash) requeue

What Sidekiq does NOT do

âŒ No job locking
âŒ No exactly-once guarantee
âŒ No rollback of DB changes

Thatâ€™s your job via:

idempotency

unique DB constraints

transactions

Final one-paragraph answer (perfect interview answer)

Sidekiq uses reliable fetch and Redis heartbeats. When a worker takes a job, it atomically moves it to an in-progress state and records the worker and process in Redis. If Sidekiq crashes, the heartbeat stops but the job remains unacknowledged. On restart, Sidekiq detects stale worker entries and re-queues those in-progress jobs back to their original queues, allowing them to run again.