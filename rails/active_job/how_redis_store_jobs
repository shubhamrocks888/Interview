When perform_later is called â†’ what exactly happens?
MyJob.perform_later(1)


Flow:

Rails â†’ ActiveJob â†’ Sidekiq adapter â†’ Redis


Sidekiq serializes the job into JSON and stores it in different Redis data structures based on job state.

1ï¸âƒ£ Where are NEW / PENDING jobs stored?
ğŸ‘‰ Redis LIST

Queue key format

queue:<queue_name>


Example:

queue:default
queue:critical


Command used:

LPUSH queue:default <job_json>


Example job JSON:

{
  "class": "MyJob",
  "args": [1],
  "jid": "a1b2c3",
  "queue": "default",
  "created_at": 1700000000,
  "enqueued_at": 1700000005,
  "retry": true
}


âœ”ï¸ FIFO behavior
âœ”ï¸ Fast push/pop
âœ”ï¸ Multiple workers can pop safely

2ï¸âƒ£ What happens when a worker picks the job?
ğŸ‘‰ Job is REMOVED from queue list
RPOP queue:default


Now job is:

In worker memory

Being executed

NOT stored in Redis

âš ï¸ This is why crashes matter (weâ€™ll cover reliability next)

3ï¸âƒ£ Where are RUNNING jobs tracked?
ğŸ‘‰ Redis HASH + SET

Keys:

workers
processes


Example:

HSET workers <process_id>:<thread_id> <job_payload>


Purpose:

Sidekiq Web UI

Detect stuck jobs

Graceful shutdown

âœ”ï¸ Purely monitoring
âœ”ï¸ Not persistence

4ï¸âƒ£ Where are RETRY jobs stored?

If job fails and retry: true ğŸ‘‡

ğŸ‘‰ Redis SORTED SET

Key:

retry


Command:

ZADD retry <retry_at_timestamp> <job_json>


Why sorted set?

Jobs must run in the future

Sorted by execution time

Example:

retry
  score: 1700000600 â†’ job_json


Sidekiq poller:

Periodically checks retry

Moves due jobs back to queue

âœ”ï¸ Delayed retries
âœ”ï¸ Time-based scheduling

5ï¸âƒ£ Where are SCHEDULED / DELAYED jobs stored?

Example:

MyJob.set(wait: 10.minutes).perform_later

ğŸ‘‰ Redis SORTED SET

Key:

schedule


Command:

ZADD schedule <run_at_timestamp> <job_json>


Very similar to retry set, but:

schedule â†’ first execution

retry â†’ failed execution

6ï¸âƒ£ Where are FAILED (Dead) jobs stored?

After retries exhausted ğŸ‘‡

ğŸ‘‰ Redis SORTED SET

Key:

dead


Command:

ZADD dead <failed_at_timestamp> <job_json>


Used by:

Sidekiq Web UI

Manual retries

Debugging

Default behavior:

Jobs kept for 6 months

Max 10,000 jobs (older pruned)

7ï¸âƒ£ Where are COMPLETED jobs stored?
âŒ NOWHERE âŒ

This is important.

âœ”ï¸ Successful jobs:

Are removed from memory

Not stored in Redis

No history kept

Reason:

High throughput

Redis memory efficiency

ğŸ‘‰ Sidekiq assumes success is the normal case

8ï¸âƒ£ Summary Table (ğŸ”¥ interview-ready)

| Job State     | Redis Structure | Redis Key              |
| ------------- | --------------- | ---------------------- |
| Pending       | List            | `queue:<name>`         |
| Running       | Hash / Set      | `workers`, `processes` |
| Scheduled     | Sorted Set      | `schedule`             |
| Retry         | Sorted Set      | `retry`                |
| Dead (Failed) | Sorted Set      | `dead`                 |
| Completed     | âŒ Not stored    | â€”                      |


9ï¸âƒ£ Why Redis data structures are chosen?

| Redis Type | Why                  |
| ---------- | -------------------- |
| List       | Fast FIFO queue      |
| Sorted Set | Time-based execution |
| Hash       | Worker state         |
| Set        | Process tracking     |


Redis is:

In-memory

Atomic

Extremely fast

Perfect for background jobs.

10ï¸âƒ£ One-liner interview answer ğŸ’¡

Sidekiq stores pending jobs in Redis lists, scheduled and retry jobs in sorted sets keyed by timestamp, failed jobs in a dead set, running jobs in worker hashes, and successful jobs are not persisted at all.